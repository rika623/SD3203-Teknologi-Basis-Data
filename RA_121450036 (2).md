Nama : Rika Ajeng Finatih\
NIM : 121450036
Kelas : Teknologi Basis Data RA

# Three Ways of Storing and Accessing Lots of Images in Pyhton
Artikel "Three Ways of Storing and Accessing Lots of Images in Python" oleh Rebecca Stone membahas tiga cara untuk menyimpan dan mengakses banyak gambar dengan bantuan Python dalam jumlah besar. Semakin besar jumlah data gambar yang dimiliki, semakin kompleks penanganannya. Algoritma machine learning seperti convolutional neural networks (CNNs) dapat mengelola data yang besar dan bahkan belajar dari dirinya sendiri. Artikel ini juga memperkenalkan ImageNet, sebuah database gambar publik yang terkenal dikumpulkan untuk melatih model pada tugas-tugas seperti klasifikasi objek, deteksi, dan segmentasi, dan terdiri dari lebih dari 14 juta gambar. Bayangkan waktu yang dibutuhkan untuk memuat semuanya ke dalam memori untuk pelatihan, dalam batch, mungkin ratusan atau ribuan kali. Dalam artikel ini pun akan diperlihatkan bagaimana cara menyimpan gambar pada disk dalam format file .png, menyimpannya dalam lightning memory-mapped databases (LMDB), dan menyimpannya dalam format data hierarki (HDF5).  Kemudian, akan menjelajahi beberapa hal berikut:
1. Mengapa metode penyimpanan alternatif perlu dipertimbangkan.
2. Perbedaan performa saat membaca dan menulis gambar tunggal.
3. Perbedaan performa saat membaca dan menulis banyak gambar.
4. Perbandingan ketiga metode dalam penggunaan disk.

## Setup
Dalam tahapan ini diperlukannya data images untuk dapat digunakan, serta mengimport packages python yang akan digunakan. 
### A Dataset to Play With
Artikel ini menggunakan data gambar dari Canadian Institute for Advanced Research (CIFAR-10), terdiri dari 60.000 gambar berwarna dengan ukuran 32x32 piksel. Gambar-gambar ini menampilkan objek dari berbagai kelas, seperti anjing, kucing, dan pesawat terbang. Penulis menyatakan bahwa meskipun data dari CIFAR tidak termasuk dalam kategori sangat besar, namun jika menggunakan kumpulan data TinyImages yang lengkap, akan membutuhkan sekitar 400 GB ruang disk Selain itu, penulis juga memberitahu bahwa ketika kita mengekstrak folder yang sudah terdownload maka sebenarnya file tersebut bukanlah file gambar yang dapat dibaca manusia tetapi telah diserialkan dan disimpan kedalam batch menggunakan cPickle. 

Dalam artikel ini, selain mengekstrak kumpulan data CIFAR, perlu disebutkan bahwa picklemodul Python memiliki keuntungan utama karena dapat membuat serialisasi objek Python apa pun tanpa kode tambahan atau transformasi apa pun di pihak kita. Hal ini juga berpotensi menimbulkan kerugian serius karena menimbulkan risiko keamanan dan tidak mampu menangani data dalam jumlah yang sangat besar dengan baik.

```
import numpy as np
import pickle
from pathlib import Path

# Import data CIFAR yang telah di ekstrak
data_dir = Path("data/cifar-10-batches-py/")

# Fungsi buka acar disediakan
by the CIFAR hosts
def unpickle(file):
    with open(file, "rb") as fo:
        dict = pickle.load(fo, encoding="bytes")
    return dict

images, labels = [], []
for batch in data_dir.glob("data_batch_*"):
    batch_data = unpickle(batch)
    for i, flat_im in enumerate(batch_data[b"data"]):
        im_channels = []
        # Each image is flattened, with channels in order of R, G, B
        for j in range(3):
            im_channels.append(
                flat_im[j * 1024 : (j + 1) * 1024].reshape((32, 32))
            )
        # Reconstruct the original image
        images.append(np.dstack((im_channels)))
        # Save the label
        labels.append(batch_data[b"labels"][i])

print("Loaded CIFAR-10 training set:")
print(f" - np.shape(images)     {np.shape(images)}")
print(f" - np.shape(labels)     {np.shape(labels)}")
```
Semua gambar sekarang ada di RAM dalam variabel images, dengan meta data yang sesuai di labelnya, dan siap untuk dimanipulasi. Langkah selanjutnya yaitu menginstall packages Python untuk menggunakan ketiga metode tersebut.

### Setup for Storing Images on Disk
Pastikan bahwa Python 3.X telah diinstal. Selanjutnya, kita akan melakukan manipulasi gambar dengan menggunakan `Pillow`.
```
$ pip install Pillow
```
Alternatif lain yaitu dengan mengintall `Anaconda`.
```
$ conda install -c conda-forge pillow
```
Penulis memberikan catatan berikut: PIL merupakan versi asli dari Python Imaging Library, yang tidak lagi dipertahankan dan tidak kompatibel dengan Python 3.x. Jika Anda sebelumnya telah menginstal PIL, pastikan untuk menghapus instalasi tersebut sebelum menginstal Pillow, karena keduanya tidak dapat beroperasi bersamaan.

Setelah langkah-langkah tersebut selesai, kita siap untuk menyimpan dan membaca data gambar dari disk.

### Getting Started With LMDB
LMDB (Lightning Memory-Mapped Database) atau biasa dikenal dengan Lightning Database memiliki kecepatan dan penggunaan file yang dapat ditelakkan kedalam memori. Berbeda dengan database relasional, LMDB menyimpan kunci-nilai dalam sebuah struktur pohon B+. Pohon B+ merupakan grafik yang menyerupai pohon dan disimpan di dalam memori, memungkinkan penjelajahan antar simpul dengan cepat. Komponen kunci pada pohon B+ disesuaikan dengan ukuran halaman sistem operasi, meningkatkan efisiensi akses data. Efisiensi LMDB juga didorong oleh penggunaan pemetaan memori, yang mengembalikan penunjuk langsung ke alamat memori kunci dan nilai tanpa perlu menyalin data. LMDB mengoptimalkan kinerjanya dengan memanfaatkan sistem file dan implementasi yang mendasarinya. Bagi yang ingin mendalami topik ini lebih lanjut, terdapat artikel tentang pohon B+ dan visualisasi penyisipan simpul yang dapat menjadi sumber belajar yang bermanfaat. Selanjutnya, kita menggunakan `python binding` untuk perpustakaan LMDB C, yang dapat diinstal melalui pip.

```
$ pip install lmdb
```
Opsi dengan menggunakan `Anaconda`:
```
$ conda install -c conda-forge python-lmdb
```
Kemudian kita dapat memeriksa apakah kita dapat melakukannya `import lmdb` dari shell python.

### Getting Started With HDF5
HDF5 merupakan sinagkatan dari hierarchical Data Format, dimana format file tersebut disebuat sebagai HDF4 atau HDF5. HDF4 dan HDF5 merupakan sama tetapi versinya saja yang berbeda. HDF berasal dari National Center for Supercomputing Applications, digunakan sebagai format data ilmiah yang portabel dan ringkas.

File HDF terdiri dari dua jenis objek:
1. Dataset
2. Groups

Dataset adalah array multidimensional, sementara grup terdiri dari dataset atau Groups lainnya. Array multidimensional dengan ukuran dan jenis apa pun dapat disimpan sebagai dataset, namun dimensi dan jenis harus seragam dalam satu dataset. Meskipun demikian, karena Groups dan dataset dapat bersarang, kita masih dapat mendapatkan keberagaman yang mungkin diperlukan.
```
$ pip install h5py
```
Dengan menggunakan `Anaconda`.
```
$ conda install -c conda-forge h5py
```
Jika kita sudah bisa mengimportkan h5py dari shell Python, maka sudah dikatakan berhasil dan telah diatur dengan benar.

## Storing a Single Image
Dalam artikel ini penulis menuliskan beberapa tugas dasar yang penting, seperti menentukan waktu yang diperlukan untuk membaca dan menulis file, serta memperkirakan jumlah memori disk yang akan digunakan. Ini juga berfungsi sebagai pengenalan dasar tentang cara kerja metode, dengan contoh kode yang menunjukkan cara penggunaannya. Untuk eksperimen, kita dapat membandingkan kinerja antara berbagai jumlah file, mulai dari satu gambar hingga 100.000 gambar, dengan faktor 10. Sebagai contoh, dengan menggunakan lima kumpulan CIFAR-10 yang berisi total 50.000 gambar, kita bisa mengambil setiap gambar dua kali untuk mencapai jumlah 100.000 gambar. Langkah penting lainnya adalah membuat folder untuk setiap metode yang akan berisi semua file atau gambar database, dan menyimpan jalur ke direktori tersebut dalam sebuah variabel.
```
from pathlib import Path

disk_dir = Path("data/disk/")
lmdb_dir = Path("data/lmdb/")
hdf5_dir = Path("data/hdf5/")
```
`Path` tidak secara otomatis membuat folder untuk kita kecuali kita secara khusus memintanya untuk melakukannya.
```
disk_dir.mkdir(parents=True, exist_ok=True)
lmdb_dir.mkdir(parents=True, exist_ok=True)
hdf5_dir.mkdir(parents=True, exist_ok=True)
```
Sekarang kita dapat melanjutkan dengan menjalankan eksperimen sebenarnya, menggunakan contoh kode untuk melakukan tugas dasar dengan tiga metode yang berbeda. Kita dapat memanfaatkan modul `timeit`, yang tersedia dalam pustaka standar Python, untuk membantu mengukur waktu eksperimen.

Meskipun fokus utama artikel ini bukanlah mempelajari API dari berbagai paket Python, akan sangat membantu jika kita memahami bagaimana paket tersebut dapat diimplementasikan. Oleh karena itu, kita akan membahas prinsip umum beserta seluruh kode yang digunakan untuk menjalankan eksperimen penyimpanan.

### Storing to Disk
Dalam percobaan ini, kita memiliki satu gambar `image` yang saat ini tersimpan di memori sebagai array NumPy. Kita ingin menyimpannya ke disk sebagai file `.png` dan memberikan nama yang unik dengan menggunakan `image_id`. Ini dapat dilakukan dengan menggunakan paket `Pillow `yang telah kita instal sebelumnya.
```
from PIL import Image
import csv
def store_single_disk(image, image_id, label):
    """ Stores a single image as a .png file on disk.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    Image.fromarray(image).save(disk_dir / f"{image_id}.png")
    with open(disk_dir / f"{image_id}.csv", "wt") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        writer.writerow([label])
```
Kode di atas menunjukkan cara menyimpan gambar, tetapi ketika menyimpan gambar, misalnya dengan label gambar, ada beberapa cara untuk menyimpan data tambahan tersebut. Salah satunya adalah dengan memasukkan label ke dalam nama gambar secara langsung. Namun, pendekatan ini memiliki kelemahan besar karena memaksa kita untuk menangani semua file setiap kali kita melakukan sesuatu dengan label. Menyimpan label dalam file terpisah memungkinkan kita untuk bekerja dengan label saja, tanpa harus memuat gambar. Seperti yang telah kita lakukan di atas, kita telah menyimpan label dalam file .`csv` terpisah untuk percobaan ini.

### Storing to LMDB
alam kasus ini, kunci akan menjadi pengidentifikasi unik untuk setiap gambar, dan nilainya akan berupa gambar itu sendiri. Keduanya diharapkan berupa string, jadi praktek umum adalah membuat serial nilai sebagai string, lalu membatalkan serialisasi saat membacanya kembali. Kita dapat menggunakan `pickle` untuk melakukan serialisasi ini.

Untuk memfasilitasi pengelolaan gambar dan metadatanya, kita dapat membuat kelas dasar Python. Berikut adalah contoh kerangka dasar untuk kelas tersebut:
```
class CIFAR_Image:
    def __init__(self, image, label):
        # Dimensions of image for reconstruction - not really necessary 
        # for this dataset, but some datasets may include images of 
        # varying sizes
        self.channels = image.shape[2]
        self.size = image.shape[:2]
        self.image = image.tobytes()
        self.label = label
    def get_image(self):
        """ Returns the image as a numpy array. """
        image = np.frombuffer(self.image, dtype=np.uint8)
        return image.reshape(*self.size, self.channels)
```

Karena LMDB menggunakan pemetaan memori, yang membutuhkan estimasi jumlah memori yang akan digunakan oleh database, ini cukup sederhana untuk kasus kami, tetapi dapat menjadi rumit dalam kasus yang lain, seperti yang akan dijelaskan lebih lanjut nanti. LMDB menyebut ini sebagai map_size. Selain itu, proses baca dan tulis dengan LMDB dilakukan dalam transaksi, yang dapat dianggap seperti serangkaian operasi pada database tradisional.

Berikut adalah contoh kode untuk menyimpan satu gambar ke dalam LMDB:
```
import lmdb
import pickle
def store_single_lmdb(image, image_id, label):
    """ Stores a single image to a LMDB.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    map_size = image.nbytes * 10
    # Create a new LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), map_size=map_size)
    # Start a new write transaction
    with env.begin(write=True) as txn:
        # All key-value pairs need to be strings
        value = CIFAR_Image(image, label)
        key = f"{image_id:08}"
        txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()
```

### Storing With HDF5
Dalam format HDF5, kita dapat menyimpan lebih dari satu kumpulan data. Kita bisa membuat dua grup data: satu untuk gambar dan satu lagi untuk metadatanya.
```
import h5py
def store_single_hdf5(image, image_id, label):
    """ Stores a single image to an HDF5 file.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "w")
    # Create a dataset in the file
    dataset = file.create_dataset(
        "image", np.shape(image), h5py.h5t.STD_U8BE, data=image
    )
    meta_set = file.create_dataset(
        "meta", np.shape(label), h5py.h5t.STD_U8BE, data=label
    )
    file.close()
```
`h5py.h5t.STD_U8BE` menentukan jenis data yang akan disimpan dalam kumpulan data, yang dalam hal ini adalah bilangan bulat 8-bit yang tidak ditandatangani.

### Experiments for Storing a Single Image
Dengan kode dibawah, kita dapat menggabungkan ketiga fungsi untuk menyimpan satu gambar ke dalam sebuah dictionary.
```
_store_single_funcs = dict(
    disk=store_single_disk, lmdb=store_single_lmdb, hdf5=store_single_hdf5
)
```
Selanjutnya, kita dapat coba menyimpan gambar pertama dari dataset CIFAR beserta label terkait, kemudian menyimpannya dengan tiga cara berbeda:
```
from timeit import timeit
store_single_timings = dict()
for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_store_single_funcs[method](image, 0, label)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    store_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```
Dari hasil kode yang telah dilakukan, dapat disimpulkan bahwa:
1. Semua metode ini memiliki kinerja yang cukup cepat.
2. Dalam hal penggunaan disk, LMDB menggunakan lebih banyak sumber daya.

Meskipun LMDB menunjukkan sedikit keunggulan dalam kinerja, kita belum meyakinkan bahwa tidak ada alasan untuk hanya menyimpan gambar di disk. Format yang dapat dibaca oleh manusia, seperti PNG, memungkinkan kita untuk membuka dan melihat gambar dengan mudah dari berbagai jenis sistem file.

## Storing Many Images
Setelah melihat kode yang menggunakan berbagai metode penyimpanan untuk menyimpan satu gambar, langkah selanjutnya adalah menyesuaikan kode untuk menyimpan banyak gambar, dan kemudian menjalankan eksperimen berwaktu.
### Adjusting the Code for Many Images
Kita ingin menjaga konsistensi dalam struktur database file sehingga setiap gambar dapat dimasukkan ke dalam satu atau beberapa file, bukan membuat file database yang berbeda untuk setiap gambar. Oleh karena itu, perlu dilakukan penyesuaian kode dengan membuat tiga fungsi baru: `store_many_disk()`, `store_many_lmdb()`, dan `store_many_hdf5()`.
```
store_many_disk(images, labels):
    """ Stores an array of images to disk
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)
    # Save all the images one by one
    for i, image in enumerate(images):
        Image.fromarray(image).save(disk_dir / f"{i}.png")
    # Save all the labels to the csv file
    with open(disk_dir / f"{num_images}.csv", "w") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for label in labels:
            # This typically would be more than just one value per row
            writer.writerow([label])
def store_many_lmdb(images, labels):
    """ Stores an array of images to LMDB.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)
    map_size = num_images * images[0].nbytes * 10
    # Create a new LMDB DB for all the images
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), map_size=map_size)
    # Same as before — but let's write all the images in a single transaction
    with env.begin(write=True) as txn:
        for i in range(num_images):
            # All key-value pairs need to be Strings
            value = CIFAR_Image(images[i], labels[i])
            key = f"{i:08}"
            txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()
def store_many_hdf5(images, labels):
    """ Stores an array of images to HDF5.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)
    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "w")
    # Create a dataset in the file
    dataset = file.create_dataset(
        "images", np.shape(images), h5py.h5t.STD_U8BE, data=images
    )
    meta_set = file.create_dataset(
        "meta", np.shape(labels), h5py.h5t.STD_U8BE, data=labels
    )
    file.close()
```
Untuk menyimpan lebih dari satu file ke disk, metode file gambar diubah agar dapat mengulangi setiap gambar dalam daftar. Saat menggunakan LMDB, kita juga perlu melakukan iterasi karena kita membuat objek CIFAR_Image untuk setiap gambar dan metadata-nya.
Sebaliknya, ketika menggunakan metode HDF5, penyesuaian minimal diperlukan. Faktanya, hampir tidak ada penyesuaian sama sekali! File HDF5 tidak terbatas pada ukuran file, kecuali batasan eksternal atau ukuran kumpulan data, sehingga semua gambar dapat dimasukkan ke dalam satu kumpulan data seperti sebelumnya.

### Preparing the Dataset
Langkah pertama adalah melakukan penggandaan ukuran kumpulan data kita agar kita dapat menguji hingga 100.000 gambar.
```
cutoffs = [10, 100, 1000, 10000, 100000]

# Menggandakan Gambar sampai mendapatkan 10.000 gambar
images = np.concatenate((images, images), axis=0)
labels = np.concatenate((labels, labels), axis=0)

# Pastikan Anda benar-benar memiliki 100.000 gambar dan label
print(np.shape(images))
print(np.shape(labels))
```
### Experiment for Storing Many Images
lalu akan membuat dictionary yang menangani semua fungsi `store_many_` :
```
_store_many_funcs = dict(
    disk=store_many_disk, lmdb=store_many_lmdb, hdf5=store_many_hdf5
)
from timeit import timeit
store_many_timings = {"disk": [], "lmdb": [], "hdf5": []}
for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_store_many_funcs[method](images_, labels_)",
            setup="images_=images[:cutoff]; labels_=labels[:cutoff]",
            number=1,
            globals=globals(),
        )
        store_many_timings[method].append(t)
        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, Time usage: {t}")
```
Dari kode tersebut, akan ada total 300.000 gambar yang disimpan. Grafik yang ditampilkan dalam artikel terdiri dari dua bagian. Diagram pertama menunjukkan perbedaan besar dalam waktu penyimpanan antara metode penyimpanan normal dan metode yang disesuaikan. Fokus utama adalah pada perbedaan antara menyimpan dalam format .png dan menggunakan LMDB atau HDF5. Diagram kedua menunjukkan perubahan waktu dalam skala logaritmik, menunjukkan bahwa meskipun HDF5 memulai prosesnya dengan kecepatan lebih rendah daripada LMDB, namun dengan meningkatnya jumlah gambar, HDF5 menjadi sedikit lebih cepat. Ini adalah alasan mengapa LMDB dan HDF5 layak untuk dipertimbangkan. Berikut adalah kode yang menghasilkan grafik tersebut.
```
import matplotlib.pyplot as plt
def plot_with_legend(
    x_range, y_data, legend_labels, x_label, y_label, title, log=False
):
    """ Displays a single plot with multiple datasets and matching legends.
        Parameters:
        --------------
        x_range         list of lists containing x data
        y_data          list of lists containing y values
        legend_labels   list of string legend labels
        x_label         x axis label
        y_label         y axis label
    """
    plt.style.use("seaborn-whitegrid")
    plt.figure(figsize=(10, 7))
    if len(y_data) != len(legend_labels):
        raise TypeError(
            "Error: number of data sets does not match number of labels."
        )
    all_plots = []
    for data, label in zip(y_data, legend_labels):
        if log:
            temp, = plt.loglog(x_range, data, label=label)
        else:
            temp, = plt.plot(x_range, data, label=label)
        all_plots.append(temp)
    plt.title(title)
    plt.xlabel(x_label)
    plt.ylabel(y_label)
    plt.legend(handles=all_plots)
    plt.show()
# Getting the store timings data to display
disk_x = store_many_timings["disk"]
lmdb_x = store_many_timings["lmdb"]
hdf5_x = store_many_timings["hdf5"]
plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Storage time",
    log=False,
)
plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Log storage time",
    log=True,
)
```
## Reading a Single Image
Membaca kembali satu gambar ke dalam array untuk masing-masing dari tiga metode.
### Reading From Disk
Dari ketiga metode, LMDB memerlukan kerja keras paling banyak saat membaca kembali file gambar dari memori, karena langkah serialisasi yang diperlukan. Langkah pertama kita adalah membaca gambar dan metadata terkait dari file `.png` dan `.csv`.
```
def read_single_disk(image_id):
    """ Stores a single image to disk.
        Parameters:
        ---------------
        image_id    integer unique ID for image
        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    image = np.array(Image.open(disk_dir / f"{image_id}.png"))
    with open(disk_dir / f"{image_id}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        label = int(next(reader)[0])
    return image, label
```
### Reading From LMDB
Selanjutnya, kita akan membaca gambar dan metadata yang sama dari LMDB dengan membuka lingkungan dan memulai transaksi baca:
```
def read_single_lmdb(image_id):
    """ Stores a single image to LMDB.
        Parameters:
        ---------------
        image_id    integer unique ID for image
        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), readonly=True)
    # Start a new read transaction
    with env.begin() as txn:
        # Encode the key the same way as we stored it
        data = txn.get(f"{image_id:08}".encode("ascii"))
        # Remember it's a CIFAR_Image object that is loaded
        cifar_image = pickle.loads(data)
        # Retrieve the relevant bits
        image = cifar_image.get_image()
        label = cifar_image.label
    env.close()
    return image, label
```
### Reading From HDF5
Di tahap ini, kita akan membuka dan membaca file HDF5 serta mengurai gambar dan metadata yang sama.
```
def read_single_hdf5(image_id):
    """ Stores a single image to HDF5.
        Parameters:
        ---------------
        image_id    integer unique ID for image
        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "r+")
    image = np.array(file["/image"]).astype("uint8")
    label = int(np.array(file["/meta"]).astype("uint8"))
    return image, label
```
kemudian kita membuat kamus yang berisi semua fungsi baca : 
```
_read_single_funcs = dict(
    disk=read_single_disk, lmdb=read_single_lmdb, hdf5=read_single_hdf5
)
```
### Experiment for Reading a Single Image
Kode enkripsi yang digunakan:
```
from timeit import timeit
read_single_timings = dict()
for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_read_single_funcs[method](0)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    read_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```
Dari hasil percobaan, waktu yang diperlukan untuk membaca satu gambar untuk metode disk adalah sekitar 1,61970 mdtk, untuk LMDB sekitar 4,52063 mdtk, dan untuk HDF5 sekitar 1,98036 mdtk. Kita dapat melihat bahwa membaca langsung dari file .png dan .csv dari disk sedikit lebih cepat, tetapi ketiga metode tersebut masih beroperasi dengan sangat cepat.

## Reading Many Images
Tahap ini merupakan kode untuk membaca banyak gambar sekaligus. Hal ini mungkinan merupakan tindakan yang paling sering dilakukan, jadi performa runtime sangatlah penting.
### Adjusting the Code for Many Images
Menggunakan fungsi` read_many_` untuk melakukan percobaan:
```
def read_many_disk(num_images):
    """ Reads image from disk.
        Parameters:
        ---------------
        num_images   number of images to read
        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []
    # Loop over all IDs and read each image in one by one
    for image_id in range(num_images):
        images.append(np.array(Image.open(disk_dir / f"{image_id}.png")))
    with open(disk_dir / f"{num_images}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for row in reader:
            labels.append(int(row[0]))
    return images, labels
def read_many_lmdb(num_images):
    """ Reads image from LMDB.
        Parameters:
        ---------------
        num_images   number of images to read
        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), readonly=True)
    # Start a new read transaction
    with env.begin() as txn:
        # Read all images in one single transaction, with one lock
        # We could split this up into multiple transactions if needed
        for image_id in range(num_images):
            data = txn.get(f"{image_id:08}".encode("ascii"))
            # Remember that it's a CIFAR_Image object 
            # that is stored as the value
            cifar_image = pickle.loads(data)
            # Retrieve the relevant bits
            images.append(cifar_image.get_image())
            labels.append(cifar_image.label)
    env.close()
    return images, labels
def read_many_hdf5(num_images):
    """ Reads image from HDF5.
        Parameters:
        ---------------
        num_images   number of images to read
        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []
    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "r+")
    images = np.array(file["/images"]).astype("uint8")
    labels = np.array(file["/meta"]).astype("uint8")
    return images, labels
_read_many_funcs = dict(
    disk=read_many_disk, lmdb=read_many_lmdb, hdf5=read_many_hdf5
)
```
### Experiment for Reading Many Images
```
from timeit import timeit
read_many_timings = {"disk": [], "lmdb": [], "hdf5": []}
for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_read_many_funcs[method](num_images)",
            setup="num_images=cutoff",
            number=1,
            globals=globals(),
        )
        read_many_timings[method].append(t)
        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, No. images: {cutoff}, Time usage: {t}")
```
Berikut adalah penjelasan tentang dua grafik yang ditampilkan:
1. *Diagram Pertama*: Diagram ini menunjukkan perbedaan besar dalam waktu baca antara metode penyimpanan konvensional dan metode yang disesuaikan. Perbedaan utama terlihat antara membaca dari format .png dan menggunakan LMDB atau HDF5. Metode konvensional, yaitu membaca langsung dari file .png, terlihat memiliki waktu baca yang lebih cepat daripada LMDB atau HDF5.
2. *Diagram Kedua:* Diagram ini menunjukkan perubahan waktu dalam skala logaritmik, menggambarkan perbedaan relatif saat jumlah gambar berkurang. Meskipun HDF5 memulai dengan kecepatan yang lebih rendah daripada LMDB, namun dengan jumlah gambar yang lebih banyak, HDF5 secara konsisten menjadi lebih cepat daripada LMDB dengan perbedaan yang kecil. Dalam praktiknya, waktu menulis seringkali kurang penting dibandingkan waktu membaca.

Ketika kita mempertimbangkan perbedaan antara waktu baca 40 detik dan 4 detik, kita menyadari bahwa ini juga dapat berarti perbedaan antara menunggu enam jam hingga model Anda dilatih, atau hanya empat puluh menit. Saat menyimpan gambar sebagai file .png, terdapat perbedaan yang signifikan antara waktu penulisan dan pembacaannya. Namun, perbedaannya tidak sebesar itu saat menggunakan LMDB atau HDF5. Secara keseluruhan, meskipun waktu baca lebih penting, ada alasan yang kuat untuk memilih LMDB atau HDF5 untuk menyimpan gambar.

## Considering Disk Usage
Ruang disk merupakan masalah yang sanagt valid dan relevan. dan pada bagian ini kita akan mencari ruang disk yang digunakan. 

Berikut adalah kode untuk mencari berapa banyak ruang disk yang digunakan oleh berbagai metode penyimpanan:

```
# Memory used in KB
disk_mem = [24, 204, 2004, 20032, 200296]
lmdb_mem = [60, 420, 4000, 39000, 393000]
hdf5_mem = [36, 304, 2900, 29000, 293000]
X = [disk_mem, lmdb_mem, hdf5_mem]
ind = np.arange(3)
width = 0.35
plt.subplots(figsize=(8, 10))
plots = [plt.bar(ind, [row[0] for row in X], width)]
for i in range(1, len(cutoffs)):
    plots.append(
        plt.bar(
            ind, [row[i] for row in X], width, bottom=[row[i - 1] for row in X]
        )
    )
plt.ylabel("Memory in KB")
plt.title("Disk memory used by method")
plt.xticks(ind, ("PNG", "LMDB", "HDF5"))
plt.yticks(np.arange(0, 400000, 100000))
plt.legend(
    [plot[0] for plot in plots], ("10", "100", "1,000", "10,000", "100,000")
)
plt.show()
```
Dari barplot yang dihasilkan, terlihat bahwa baik HDF5 maupun LMDB membutuhkan lebih banyak ruang disk daripada menyimpan gambar dalam format .png. Meskipun efisiensi LMDB bergantung pada caching dan ukuran halaman OS, penggunaan disknya meningkat secara signifikan dengan gambar yang lebih besar. Namun, untuk gambar berukuran 32 x 32 x 3 piksel, LMDB memberikan kinerja terbaik. Meskipun tidak diteliti secara khusus dalam eksperimen ini, berdasarkan pengalaman dengan gambar berukuran lebih besar, HDF5 cenderung sedikit lebih efisien dalam penggunaan disk daripada LMDB.

## Discussion
Ada fitur pembeda lainnya dari LMDB dan HDF5 yang perlu diketahui, dan penting juga untuk membahas secara singkat beberapa kritik terhadap kedua metode tersebut.
### Parallel Access
Dalam eksperimen yang telah dilakukan, perbandingan utama yang tidak diuji adalah pembacaan dan penulisan secara bersamaan. Dalam konteks kumpulan data yang besar, paralelisasi dapat meningkatkan efisiensi operasi. Format penyimpanan .png memungkinkan konkurensi lengkap, di mana Anda dapat membaca beberapa gambar sekaligus dari thread berbeda atau menulis beberapa file sekaligus, asalkan nama gambar berbeda.

LMDB memungkinkan beberapa pembaca di lingkungan yang sama secara bersamaan, namun hanya satu penulis yang diizinkan, tanpa adanya pembatasan pada pembaca. Ini memungkinkan waktu baca yang lebih cepat, terutama jika kumpulan data dibagi menjadi beberapa set untuk diakses secara paralel.

HDF5 juga menawarkan I/O paralel, tetapi dalam implementasinya, kunci tulis ditahan, sehingga akses dilakukan secara berurutan kecuali Anda menggunakan sistem file paralel. Solusi yang disarankan adalah membagi kumpulan data menjadi beberapa file HDF5 secara cerdas, memungkinkan setiap proses menangani satu file .h5 secara terpisah untuk meningkatkan paralelisasi.

### Documentation
Sumber utama dokumentasi untuk pengikatan Python pada LMDB dapat ditemukan di Read the Docs LMDB. Meskipun paket Python belum mencapai versi > 0.94, LMDB cukup banyak digunakan dan dianggap stabil. Untuk informasi lebih lanjut tentang teknologi LMDB itu sendiri, dokumentasi yang lebih detail tersedia di situs web teknologi LMDB, meskipun memahaminya bisa terasa rumit tanpa pengetahuan yang memadai. Di sisi lain, dokumentasi yang sangat jelas untuk HDF5 dapat ditemukan di situs dokumen h5py, serta dalam postingan blog bermanfaat oleh Christopher Lovell, yang memberikan ikhtisar bagus tentang cara menggunakan paket h5py. Buku O'Reilly, "Python dan HDF5," juga merupakan sumber yang baik untuk memulai. Meskipun tidak terdokumentasi secara lengkap seperti yang diinginkan oleh pemula, baik LMDB maupun HDF5 memiliki komunitas pengguna yang besar, sehingga pencarian lebih lanjut di Google biasanya memberikan hasil yang bermanfaat.

### A More Critical Look at Implementation
Tidak ada sistem penyimpanan yang sempurna, dan baik LMDB maupun HDF5 memiliki kelemahan masing-masing. LMDB, meskipun menawarkan pembacaan yang sangat cepat dan memastikan integritas data tanpa log transaksi, dapat menghadapi kesulitan dalam menambahkan data baru ke dalam database yang sudah ada. Dalam LMDB, data baru ditulis tanpa menimpa atau memindahkan data yang sudah ada, yang berarti Anda perlu menentukan parameter `map_size` dengan bijak sebelum menulis ke database baru. Jika `map_size` terlalu kecil, Anda mungkin akan mengalami kesalahan `MapFullError` dan harus menyimpan data baru dalam file LMDB terpisah. Hal ini dapat menjadi menyusahkan, terutama pada sistem dengan batasan jumlah memori yang dapat diklaim sekaligus.

Di sisi lain, HDF5 memungkinkan akses yang mudah seperti array Python dan mendukung operasi paralel, namun urutan akses item dapat memengaruhi kinerjanya tergantung pada cara sistem dioptimalkan. Secara umum, dengan LMDB, kinerja mungkin lebih baik saat mengakses item secara berurutan berdasarkan kunci, sementara dengan HDF5, mengakses rentang yang besar akan lebih efisien daripada membaca setiap elemen kumpulan data satu per satu.

Dalam prakteknya, pilihan antara LMDB dan HDF5 akan tergantung pada kebutuhan spesifik dan preferensi pengguna. Meskipun keduanya memiliki kelebihan dan kelemahan, keduanya tetap menjadi pilihan yang populer dan dapat diandalkan untuk penyimpanan data besar dalam berbagai aplikasi.
```
# Slightly slower
for i in range(len(dataset)):
    # Read the ith value in the dataset, one at a time
    do_something_with(dataset[i])

# This is better
data = dataset[:]
for d in data:
    do_something_with(d)
```
### Integration With Other Libraries
Ketika menghadapi kumpulan data yang sangat besar, kemungkinan besar akan dilakukan analisis yang signifikan terhadapnya. Oleh karena itu, penting untuk mempertimbangkan perpustakaan pembelajaran mendalam dan integrasi yang tersedia dengan LMDB dan HDF5.

Pertama-tama, semua paket mendukung pembacaan gambar dari disk dalam format .png, asalkan Anda mengonversinya menjadi array NumPy dengan format yang sesuai. Proses ini relatif mudah dan berlaku untuk semua metode, seperti yang telah kita bahas sebelumnya.

Berikut adalah beberapa perpustakaan pembelajaran mendalam paling populer serta integrasi LMDB dan HDF5-nya:

1. *Caffe* memiliki integrasi LMDB yang stabil dan didukung dengan baik, serta menangani langkah membaca secara transparan. Lapisan LMDB juga dapat dengan mudah diganti dengan database HDF5.
2. *Keras *menggunakan format HDF5 untuk menyimpan dan memulihkan model. Artinya, TensorFlow juga bisa melakukannya.
3. TensorFlow memiliki kelas LMDBDataset bawaan yang menyediakan antarmuka untuk membaca data masukan dari file LMDB dan dapat menghasilkan iterator dan tensor dalam batch. TensorFlow tidak memiliki kelas bawaan untuk HDF5, tetapi dapat ditulis kelas yang mewarisi kelas Dataset. 
4. Theano pada dasarnya tidak mendukung format file atau database tertentu, tetapi seperti yang disebutkan sebelumnya, Theano dapat menggunakan apa pun asalkan dibaca sebagai array berdimensi-N.

## Conclusion
Dalam artikel ini, ktia diperkenalkan dengan tiga metode untuk menyimpan dan mengakses banyak gambar menggunakan Python, dan mungkin telah mencoba beberapa di antaranya. Semua kode yang digunakan tersedia dalam notebook Jupyter atau skrip Python. Namun, perlu diingat bahwa penggunaan metode tersebut memerlukan tanggung jawab sendiri, karena beberapa GB ruang disk kita akan digunakan oleh gambar-gambar persegi kecil seperti mobil, kapal, dan sebagainya.

Selain itu, kita juga telah melihat bagaimana berbagai metode penyimpanan dapat mempengaruhi waktu baca dan tulis secara signifikan, serta pro dan kontra dari masing-masing metode yang dibahas. Meskipun penyimpanan gambar sebagai file .png mungkin tampak sebagai pendekatan yang paling familiar, metode seperti HDF5 atau LMDB memiliki manfaat kinerja yang signifikan.































